name: 'Complete Deployment Pipeline'
on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  # Step 1: Check and Use Existing Infrastructure
  check-infra:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: ${{ secrets.AWS_REGION }}
    outputs:
      s3_bucket_name: ${{ steps.infra-check.outputs.s3_bucket_name }}
      eks_cluster_name: ${{ steps.infra-check.outputs.eks_cluster_name }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
      - name: Check and Create Infrastructure
        id: infra-check
        run: |
          cd infra
          
          # Create S3 bucket for Terraform state if it doesn't exist
          aws s3 mb s3://ml-crash-course-terraform-state --region ${{ secrets.AWS_REGION }} || true
          
          # Initialize Terraform with backend using dynamic region
          terraform init \
            -backend-config="region=${{ secrets.AWS_REGION }}"
          
          # Check if resources already exist
          echo "Checking for existing resources..."
          
          S3_EXISTS=false
          EKS_EXISTS=false
          VPC_EXISTS=false
          
          # Check if S3 bucket exists
          if aws s3api head-bucket --bucket ml-crash-course-data 2>/dev/null; then
            echo "‚úÖ S3 bucket 'ml-crash-course-data' already exists"
            S3_EXISTS=true
          else
            echo "‚ùå S3 bucket 'ml-crash-course-data' does not exist"
          fi
          
          # Check if EKS cluster exists
          if aws eks describe-cluster --name ml-crash-course-cluster --region ${{ secrets.AWS_REGION }} 2>/dev/null; then
            echo "‚úÖ EKS cluster 'ml-crash-course-cluster' already exists"
            EKS_EXISTS=true
          else
            echo "‚ùå EKS cluster 'ml-crash-course-cluster' does not exist"
          fi
          
          # Check if VPC exists (by checking for VPC with the expected name pattern)
          VPC_ID=$(aws ec2 describe-vpcs --filters "Name=tag:Name,Values=ml-crash-course-cluster-vpc" --query 'Vpcs[0].VpcId' --output text --region ${{ secrets.AWS_REGION }} 2>/dev/null)
          if [ "$VPC_ID" != "None" ] && [ "$VPC_ID" != "" ]; then
            echo "‚úÖ VPC with name 'ml-crash-course-cluster-vpc' already exists (ID: $VPC_ID)"
            VPC_EXISTS=true
          else
            echo "‚ùå VPC with name 'ml-crash-course-cluster-vpc' does not exist"
          fi
          
          # Use Terraform to manage all infrastructure
          echo "üîß Managing infrastructure with Terraform..."
          
          # Check if resources are already in Terraform state
          echo "üîç Checking Terraform state for existing resources..."
          
          # Check if S3 bucket is in state
          if terraform state list | grep -q "aws_s3_bucket.ml_data"; then
            echo "‚úÖ S3 bucket already in Terraform state"
            S3_IN_STATE=true
          else
            echo "‚ùå S3 bucket not in Terraform state"
            S3_IN_STATE=false
          fi
          
          # Check if EKS cluster is in state
          if terraform state list | grep -q "aws_eks_cluster.main"; then
            echo "‚úÖ EKS cluster already in Terraform state"
            EKS_IN_STATE=true
          else
            echo "‚ùå EKS cluster not in Terraform state"
            EKS_IN_STATE=false
          fi
          
          # Check if VPC is in state
          if terraform state list | grep -q "module.vpc.aws_vpc.this"; then
            echo "‚úÖ VPC already in Terraform state"
            VPC_IN_STATE=true
          else
            echo "‚ùå VPC not in Terraform state"
            VPC_IN_STATE=false
          fi
          
          # Import existing resources if they exist but aren't in Terraform state
          if [ "$S3_EXISTS" = true ] && [ "$S3_IN_STATE" = false ]; then
            echo "üì¶ Importing existing S3 bucket into Terraform state..."
            terraform import aws_s3_bucket.ml_data ml-crash-course-data || echo "‚ö†Ô∏è  S3 bucket import failed"
          fi
          
          if [ "$EKS_EXISTS" = true ] && [ "$EKS_IN_STATE" = false ]; then
            echo "üöÄ Importing existing EKS cluster into Terraform state..."
            terraform import aws_eks_cluster.main ml-crash-course-cluster || echo "‚ö†Ô∏è  EKS cluster import failed"
            
            # Also try to import the IAM role if it exists
            terraform import aws_iam_role.eks_cluster ml-crash-course-cluster-cluster-role || echo "‚ö†Ô∏è  IAM role import failed"
          fi
          
          if [ "$VPC_EXISTS" = true ] && [ "$VPC_IN_STATE" = false ]; then
            echo "üåê Importing existing VPC into Terraform state..."
            terraform import module.vpc.aws_vpc.this[0] "$VPC_ID" || echo "‚ö†Ô∏è  VPC import failed"
          fi
          
          # Check if all resources exist and are in state
          if [ "$S3_EXISTS" = true ] && [ "$EKS_EXISTS" = true ] && [ "$VPC_EXISTS" = true ] && \
             [ "$S3_IN_STATE" = true ] && [ "$EKS_IN_STATE" = true ] && [ "$VPC_IN_STATE" = true ]; then
            echo "üéâ All resources already exist and are in Terraform state!"
            echo "‚è≠Ô∏è  Skipping Terraform apply - no changes needed"
          else
            echo "üîß Some resources need to be created or imported..."
            
            # Show what exists and what needs to be created
            echo "üìä Resource Status:"
            echo "  S3 Bucket: $([ "$S3_EXISTS" = true ] && echo "‚úÖ Exists" || echo "‚ùå Missing") $([ "$S3_IN_STATE" = true ] && echo "‚úÖ In State" || echo "‚ùå Not in State")"
            echo "  EKS Cluster: $([ "$EKS_EXISTS" = true ] && echo "‚úÖ Exists" || echo "‚ùå Missing") $([ "$EKS_IN_STATE" = true ] && echo "‚úÖ In State" || echo "‚ùå Not in State")"
            echo "  VPC: $([ "$VPC_EXISTS" = true ] && echo "‚úÖ Exists" || echo "‚ùå Missing") $([ "$VPC_IN_STATE" = true ] && echo "‚úÖ In State" || echo "‚ùå Not in State")"
            
            # Run terraform plan to see what needs to be created
            echo "üìã Planning Terraform changes..."
            terraform plan \
              -var="aws_region=${{ secrets.AWS_REGION }}" \
              -var="s3_bucket_name=ml-crash-course-data" \
              -var="eks_cluster_name=ml-crash-course-cluster" \
              -out=tfplan || {
              echo "‚ö†Ô∏è  Terraform plan failed, trying apply directly..."
              terraform apply -auto-approve \
                -var="aws_region=${{ secrets.AWS_REGION }}" \
                -var="s3_bucket_name=ml-crash-course-data" \
                -var="eks_cluster_name=ml-crash-course-cluster"
            }
            
            # Check if the plan would destroy any resources
            if [ -f tfplan ]; then
              PLAN_OUTPUT=$(terraform show tfplan 2>&1)
              if echo "$PLAN_OUTPUT" | grep -q "destroy"; then
                echo "‚ö†Ô∏è  WARNING: Terraform plan would destroy resources!"
                echo "This is unexpected. Please review the plan manually."
                echo "Plan output:"
                echo "$PLAN_OUTPUT"
                exit 1
              fi
            fi
            
            # Apply Terraform changes if plan was successful
            if [ -f tfplan ]; then
              echo "üåê Applying Terraform changes..."
              terraform apply tfplan || {
                echo "‚ö†Ô∏è  Terraform apply failed, trying to handle common issues..."
                
                # Check for specific error patterns and handle them
                APPLY_OUTPUT=$(terraform apply -auto-approve \
                  -var="aws_region=${{ secrets.AWS_REGION }}" \
                  -var="s3_bucket_name=ml-crash-course-data" \
                  -var="eks_cluster_name=ml-crash-course-cluster" 2>&1)
                APPLY_EXIT_CODE=$?
                
                if [ $APPLY_EXIT_CODE -ne 0 ]; then
                  if echo "$APPLY_OUTPUT" | grep -q "VpcLimitExceeded\|EntityAlreadyExists\|ResourceInUseException\|BucketAlreadyOwnedByYou"; then
                    echo "‚ö†Ô∏è  Some resources already exist or limits exceeded, but continuing..."
                    echo "$APPLY_OUTPUT" | grep -E "(VpcLimitExceeded|EntityAlreadyExists|ResourceInUseException|BucketAlreadyOwnedByYou)" || true
                  else
                    echo "‚ùå Terraform apply failed with unexpected error:"
                    echo "$APPLY_OUTPUT"
                    exit 1
                  fi
                else
                  echo "‚úÖ Terraform apply completed successfully"
                fi
              }
            fi
          fi
          
          echo "üéâ Infrastructure management complete!"
          
          # Get outputs from Terraform
          echo "Getting infrastructure outputs..."
          
          # Use known resource names since they are fixed in Terraform configuration
          S3_BUCKET_NAME="ml-crash-course-data"
          EKS_CLUSTER_NAME="ml-crash-course-cluster"
          
          echo "s3_bucket_name=$S3_BUCKET_NAME" >> $GITHUB_OUTPUT
          echo "eks_cluster_name=$EKS_CLUSTER_NAME" >> $GITHUB_OUTPUT
          echo "Using S3 Bucket: $S3_BUCKET_NAME"
          echo "Using EKS Cluster: $EKS_CLUSTER_NAME"
          
          # Debug: Show the actual values
          echo "üîç Debug - S3 Bucket Name: '$S3_BUCKET_NAME'"
          echo "üîç Debug - EKS Cluster Name: '$EKS_CLUSTER_NAME'"
          echo "üîç Debug - S3 Bucket Name length: ${#S3_BUCKET_NAME}"
          echo "üîç Debug - EKS Cluster Name length: ${#EKS_CLUSTER_NAME}"
          
          # Wait for EKS cluster to be ready
          echo "‚è≥ Waiting for EKS cluster to be ready..."
          aws eks wait cluster-active --name "$EKS_CLUSTER_NAME" --region ${{ secrets.AWS_REGION }}
          echo "‚úÖ EKS cluster is ready!"
          
          # Wait for node group to be ready
          echo "‚è≥ Waiting for EKS node group to be ready..."
          aws eks wait nodegroup-active --cluster-name "$EKS_CLUSTER_NAME" --nodegroup-name "$EKS_CLUSTER_NAME-node-group" --region ${{ secrets.AWS_REGION }} || {
            echo "‚ö†Ô∏è  Node group not ready yet, but continuing..."
          }
          echo "‚úÖ EKS node group is ready!"
          
          # Update kubeconfig for the cluster
          echo "üîß Updating kubeconfig for EKS cluster..."
          aws eks update-kubeconfig --region ${{ secrets.AWS_REGION }} --name "$EKS_CLUSTER_NAME"
          echo "‚úÖ Kubeconfig updated successfully!"

  # Step 2: Upload Dataset to S3
  upload-data:
    runs-on: ubuntu-latest
    needs: check-infra
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
      AWS_REGION: ${{ secrets.AWS_REGION }}
      S3_BUCKET: ${{ needs.check-infra.outputs.s3_bucket_name }}
      S3_KEY: House_Rent_Dataset.csv
      LOCAL_PATH: data/House_Rent_Dataset.csv
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'
      - name: Install dependencies
        run: pip install boto3
      - name: Upload data to S3
        run: |
          echo "Uploading to S3 bucket: $S3_BUCKET"
          python upload_data_to_s3.py
        env:
          S3_BUCKET: ${{ needs.check-infra.outputs.s3_bucket_name }}
          S3_KEY: House_Rent_Dataset.csv
          LOCAL_PATH: data/House_Rent_Dataset.csv

  # Step 3: Build and Push Docker Images
  build-and-push:
    runs-on: ubuntu-latest
    needs: [check-infra, upload-data]
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
      ECR_REPO_SPARK: ml-crash-course-spark
      ECR_REPO_API: ml-crash-course-api
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      - name: Create ECR repositories
        run: |
          # Create Spark jobs repository
          aws ecr describe-repositories --repository-names $ECR_REPO_SPARK --region $AWS_REGION || \
          aws ecr create-repository --repository-name $ECR_REPO_SPARK --region $AWS_REGION
          
          # Create Model API repository
          aws ecr describe-repositories --repository-names $ECR_REPO_API --region $AWS_REGION || \
          aws ecr create-repository --repository-name $ECR_REPO_API --region $AWS_REGION
      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2
      - name: Build and push Spark job image
        run: |
          echo "Building Spark job image..."
          
          # Check if image already exists in ECR
          ECR_IMAGE_URI="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPO_SPARK:latest"
          echo "Checking if Spark image exists: $ECR_IMAGE_URI"
          
          # Check if image exists and get its creation date
          if aws ecr describe-images --repository-name $ECR_REPO_SPARK --image-ids imageTag=latest --region $AWS_REGION 2>/dev/null; then
            echo "‚úÖ Spark job image exists in ECR"
            
            # Check if Dockerfile or requirements have changed recently
            DOCKERFILE_TIME=$(stat -c %Y spark_jobs/Dockerfile 2>/dev/null || echo "0")
            REQUIREMENTS_TIME=$(stat -c %Y spark_jobs/requirements.txt 2>/dev/null || echo "0")
            LATEST_TIME=$((DOCKERFILE_TIME > REQUIREMENTS_TIME ? DOCKERFILE_TIME : REQUIREMENTS_TIME))
            
            # Get image creation time (approximate - use current time minus 1 hour as fallback)
            IMAGE_TIME=$(date -d "1 hour ago" +%s)
            
            if [ $LATEST_TIME -gt $IMAGE_TIME ]; then
              echo "üì¶ Source files changed recently, rebuilding Spark job image..."
              docker build -t $ECR_REPO_SPARK:latest -f spark_jobs/Dockerfile ./spark_jobs || {
                echo "‚ùå Failed to build Spark job image"
                exit 1
              }
              docker tag $ECR_REPO_SPARK:latest $ECR_IMAGE_URI
              docker push $ECR_IMAGE_URI || {
                echo "‚ùå Failed to push Spark job image"
                exit 1
              }
              echo "‚úÖ Spark job image rebuilt and pushed successfully"
            else
              echo "‚è≠Ô∏è  Source files unchanged, skipping Spark job image build"
            fi
          else
            echo "üì¶ Spark job image not found, building..."
            docker build -t $ECR_REPO_SPARK:latest -f spark_jobs/Dockerfile ./spark_jobs || {
              echo "‚ùå Failed to build Spark job image"
              exit 1
            }
            docker tag $ECR_REPO_SPARK:latest $ECR_IMAGE_URI
            docker push $ECR_IMAGE_URI || {
              echo "‚ùå Failed to push Spark job image"
              exit 1
            }
            echo "‚úÖ Spark job image built and pushed successfully"
          fi
      - name: Build and push Model API image
        run: |
          echo "Building Model API image..."
          
          # Check if image already exists in ECR
          ECR_IMAGE_URI="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPO_API:latest"
          echo "Checking if Model API image exists: $ECR_IMAGE_URI"
          
          # Check if image exists and get its creation date
          if aws ecr describe-images --repository-name $ECR_REPO_API --image-ids imageTag=latest --region $AWS_REGION 2>/dev/null; then
            echo "‚úÖ Model API image exists in ECR"
            
            # Check if Dockerfile or requirements have changed recently
            DOCKERFILE_TIME=$(stat -c %Y model_api/Dockerfile 2>/dev/null || echo "0")
            REQUIREMENTS_TIME=$(stat -c %Y model_api/requirements.txt 2>/dev/null || echo "0")
            LATEST_TIME=$((DOCKERFILE_TIME > REQUIREMENTS_TIME ? DOCKERFILE_TIME : REQUIREMENTS_TIME))
            
            # Get image creation time (approximate - use current time minus 1 hour as fallback)
            IMAGE_TIME=$(date -d "1 hour ago" +%s)
            
            if [ $LATEST_TIME -gt $IMAGE_TIME ]; then
              echo "üì¶ Source files changed recently, rebuilding Model API image..."
              docker build -t $ECR_REPO_API:latest -f model_api/Dockerfile ./model_api || {
                echo "‚ùå Failed to build Model API image"
                exit 1
              }
              docker tag $ECR_REPO_API:latest $ECR_IMAGE_URI
              docker push $ECR_IMAGE_URI || {
                echo "‚ùå Failed to push Model API image"
                exit 1
              }
              echo "‚úÖ Model API image rebuilt and pushed successfully"
            else
              echo "‚è≠Ô∏è  Source files unchanged, skipping Model API image build"
            fi
          else
            echo "üì¶ Model API image not found, building..."
            docker build -t $ECR_REPO_API:latest -f model_api/Dockerfile ./model_api || {
              echo "‚ùå Failed to build Model API image"
              exit 1
            }
            docker tag $ECR_REPO_API:latest $ECR_IMAGE_URI
            docker push $ECR_IMAGE_URI || {
              echo "‚ùå Failed to push Model API image"
              exit 1
            }
            echo "‚úÖ Model API image built and pushed successfully"
          fi

  # Step 4: Deploy to EKS
  deploy-to-eks:
    runs-on: ubuntu-latest
    needs: [check-infra, upload-data, build-and-push]
    env:
      AWS_REGION: ${{ secrets.AWS_REGION }}
      AWS_ACCOUNT_ID: ${{ secrets.AWS_ACCOUNT_ID }}
      ECR_REPO_API: ml-crash-course-api
      EKS_CLUSTER_NAME: ${{ needs.check-infra.outputs.eks_cluster_name }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}
      - name: Ensure infrastructure is ready
        run: |
          echo "üîç Ensuring infrastructure is ready..."
          
          # Check if EKS cluster exists and is active
          CLUSTER_STATUS=$(aws eks describe-cluster \
            --name $EKS_CLUSTER_NAME \
            --region $AWS_REGION \
            --query 'cluster.status' \
            --output text 2>/dev/null || echo "NOT_FOUND")
          
          if [ "$CLUSTER_STATUS" != "ACTIVE" ]; then
            echo "‚ùå EKS cluster is not active (status: $CLUSTER_STATUS)"
            echo "üîß Please ensure the infrastructure step runs successfully first"
            exit 1
          fi
          
          echo "‚úÖ EKS cluster is active!"
          
          # Check if node group exists (but don't fail if it doesn't)
          NODEGROUP_STATUS=$(aws eks describe-nodegroup \
            --cluster-name $EKS_CLUSTER_NAME \
            --nodegroup-name "$EKS_CLUSTER_NAME-node-group" \
            --region $AWS_REGION \
            --query 'nodegroup.status' \
            --output text 2>/dev/null || echo "NOT_FOUND")
          
          if [ "$NODEGROUP_STATUS" = "NOT_FOUND" ]; then
            echo "‚ö†Ô∏è  Node group not found - will be created in infrastructure step"
          elif [ "$NODEGROUP_STATUS" != "ACTIVE" ]; then
            echo "‚ö†Ô∏è  Node group exists but not active (status: $NODEGROUP_STATUS)"
          else
            echo "‚úÖ Node group is active!"
          fi
          
          echo "‚úÖ Infrastructure check completed - proceeding with deployment"
      - name: Create infrastructure if needed
        run: |
          echo "üîß Checking if infrastructure needs to be created..."
          
          # Check if node group exists
          NODEGROUP_STATUS=$(aws eks describe-nodegroup \
            --cluster-name $EKS_CLUSTER_NAME \
            --nodegroup-name "$EKS_CLUSTER_NAME-node-group" \
            --region $AWS_REGION \
            --query 'nodegroup.status' \
            --output text 2>/dev/null || echo "NOT_FOUND")
          
          if [ "$NODEGROUP_STATUS" = "NOT_FOUND" ]; then
            echo "üîß Node group not found, creating infrastructure..."
            
            # Force Terraform apply to create the node group
            echo "üîß Running Terraform apply to create node group..."
            
            # Setup Terraform
            echo "üîß Setting up Terraform..."
            curl -fsSL https://apt.releases.hashicorp.com/gpg | sudo apt-key add -
            sudo apt-add-repository "deb [arch=amd64] https://apt.releases.hashicorp.com $(lsb_release -cs) main"
            sudo apt-get update && sudo apt-get install -y terraform
            
            # Create infrastructure
            cd infra
            terraform init -backend-config="region=${{ secrets.AWS_REGION }}"
            
            echo "üîç Running Terraform plan..."
            terraform plan \
              -var="aws_region=${{ secrets.AWS_REGION }}" \
              -var="s3_bucket_name=ml-crash-course-data" \
              -var="eks_cluster_name=ml-crash-course-cluster"
            
            echo "üîß Running Terraform apply..."
            terraform apply -auto-approve \
              -var="aws_region=${{ secrets.AWS_REGION }}" \
              -var="s3_bucket_name=ml-crash-course-data" \
              -var="eks_cluster_name=ml-crash-course-cluster" || {
              echo "‚ùå Terraform apply failed"
              echo "üîç Checking Terraform state..."
              terraform state list
              echo "üîç Checking Terraform outputs..."
              terraform output
              exit 1
            }
            cd ..
            
            echo "‚úÖ Terraform apply completed"
          else
            echo "‚úÖ Infrastructure already exists"
          fi
          
          # Wait for node group to be ready
          echo "‚è≥ Waiting for node group to be ready..."
          MAX_ATTEMPTS=20
          ATTEMPT=0
          
          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            NODEGROUP_STATUS=$(aws eks describe-nodegroup \
              --cluster-name $EKS_CLUSTER_NAME \
              --nodegroup-name "$EKS_CLUSTER_NAME-node-group" \
              --region $AWS_REGION \
              --query 'nodegroup.status' \
              --output text 2>/dev/null || echo "NOT_FOUND")
            
            echo "üìä Node group status: $NODEGROUP_STATUS (attempt $((ATTEMPT+1))/$MAX_ATTEMPTS)"
            
            if [ "$NODEGROUP_STATUS" = "ACTIVE" ]; then
              echo "‚úÖ Node group is active!"
              break
            fi
            
            ATTEMPT=$((ATTEMPT+1))
            sleep 60
          done
          
          if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
            echo "‚ö†Ô∏è  Timeout waiting for node group to be ready, but continuing..."
          fi
      - name: Verify EKS cluster access
        run: |
          echo "Verifying access to EKS cluster: $EKS_CLUSTER_NAME"
          
          # Update kubeconfig first
          echo "üîß Updating kubeconfig for EKS cluster..."
          aws eks update-kubeconfig --region $AWS_REGION --name $EKS_CLUSTER_NAME
          
          # Test cluster access
          kubectl get nodes || {
            echo "‚ö†Ô∏è  Could not access EKS cluster, checking cluster status..."
            aws eks describe-cluster --name $EKS_CLUSTER_NAME --region $AWS_REGION
            echo "Cluster access failed, but continuing..."
          }
      - name: Check EKS cluster resources
        run: |
          echo "üîç Checking EKS cluster resources..."
          
          # Check available nodes
          echo "üìä Available nodes:"
          kubectl get nodes -o wide
          
          # Check node resources
          echo "üìä Node resources:"
          kubectl describe nodes | grep -A 5 "Allocated resources" || echo "‚ö†Ô∏è  Could not get resource information"
          
          # Check if we have enough resources for Airflow
          NODE_COUNT=$(kubectl get nodes --no-headers | wc -l)
          echo "üìä Total nodes: $NODE_COUNT"
          
          if [ "$NODE_COUNT" -lt 2 ]; then
            echo "‚ö†Ô∏è  Warning: Only $NODE_COUNT nodes available. Airflow may have resource constraints."
          else
            echo "‚úÖ Sufficient nodes available for Airflow deployment"
          fi
          
          # Check if we need to create node groups
          if [ "$NODE_COUNT" -eq 0 ]; then
            echo "‚ùå No nodes found in EKS cluster!"
            echo "üîß Creating node group for EKS cluster..."
            
            # Create the required IAM role for EKS node groups
            echo "üîê Creating IAM role for EKS node groups..."
            aws iam create-role \
              --role-name AmazonEKSNodeRole \
              --assume-role-policy-document '{
                "Version": "2012-10-17",
                "Statement": [
                  {
                    "Effect": "Allow",
                    "Principal": {
                      "Service": "ec2.amazonaws.com"
                    },
                    "Action": "sts:AssumeRole"
                  }
                ]
              }' || {
              echo "‚ö†Ô∏è  IAM role creation failed (may already exist)"
            }
            
            # Attach required policies
            echo "üîê Attaching policies to IAM role..."
            aws iam attach-role-policy \
              --role-name AmazonEKSNodeRole \
              --policy-arn arn:aws:iam::aws:policy/AmazonEKSWorkerNodePolicy || echo "‚ö†Ô∏è  Worker policy attachment failed"
            
            aws iam attach-role-policy \
              --role-name AmazonEKSNodeRole \
              --policy-arn arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy || echo "‚ö†Ô∏è  CNI policy attachment failed"
            
            aws iam attach-role-policy \
              --role-name AmazonEKSNodeRole \
              --policy-arn arn:aws:iam::aws:policy/AmazonEC2ContainerRegistryReadOnly || echo "‚ö†Ô∏è  ECR policy attachment failed"
            
            # Create a node group using eksctl or AWS CLI
            aws eks create-nodegroup \
              --cluster-name $EKS_CLUSTER_NAME \
              --nodegroup-name ml-nodegroup \
              --node-role arn:aws:iam::$AWS_ACCOUNT_ID:role/AmazonEKSNodeRole \
              --subnets subnet-0250220481d506c84 subnet-07b6e0ec2278b2f9a \
              --instance-types t3.small \
              --scaling-config minSize=1,maxSize=3,desiredSize=2 \
              --region $AWS_REGION || {
              echo "‚ö†Ô∏è  Failed to create node group, trying alternative approach..."
              echo "Please create node groups manually in the AWS console"
            }
          fi
          
          # Check if node group exists and is active
          echo "üîç Verifying node group status..."
          NODEGROUP_STATUS=$(aws eks describe-nodegroup \
            --cluster-name $EKS_CLUSTER_NAME \
            --nodegroup-name "$EKS_CLUSTER_NAME-node-group" \
            --region $AWS_REGION \
            --query 'nodegroup.status' \
            --output text 2>/dev/null || echo "NOT_FOUND")
          
          if [ "$NODEGROUP_STATUS" = "NOT_FOUND" ] || [ "$NODEGROUP_STATUS" != "ACTIVE" ]; then
            echo "‚ö†Ô∏è  Node group not found or not active (status: $NODEGROUP_STATUS)"
            echo "üîß Node group needs to be created via Terraform in the infrastructure step"
            echo "Please ensure the infrastructure step runs successfully to create the node group"
          else
            echo "‚úÖ Node group is active (status: $NODEGROUP_STATUS)"
          fi
          
          # Wait for nodes to be ready
          echo "‚è≥ Waiting for nodes to be ready..."
          MAX_ATTEMPTS=30
          ATTEMPT=0
          
          while [ $ATTEMPT -lt $MAX_ATTEMPTS ]; do
            READY_NODES=$(kubectl get nodes --no-headers | grep -c "Ready")
            TOTAL_NODES=$(kubectl get nodes --no-headers | wc -l)
            
            echo "üìä Node status: $READY_NODES/$TOTAL_NODES nodes ready (attempt $((ATTEMPT+1))/$MAX_ATTEMPTS)"
            
            if [ $READY_NODES -gt 0 ]; then
              echo "‚úÖ Nodes are ready!"
              break
            fi
            
            ATTEMPT=$((ATTEMPT+1))
            sleep 30
          done
          
          if [ $ATTEMPT -eq $MAX_ATTEMPTS ]; then
            echo "‚ö†Ô∏è  Timeout waiting for nodes to be ready, but continuing..."
          fi
      - name: Set up Helm
        uses: azure/setup-helm@v3
      - name: Deploy Airflow via Helm
        run: |
          echo "Deploying Airflow via Helm..."
          
          # Skip Airflow deployment for now due to Helm chart issues
          echo "‚è≠Ô∏è  Skipping Airflow deployment due to Helm chart compatibility issues"
          echo "The core ML pipeline (Model API) will be deployed without Airflow"
          echo "Airflow can be deployed separately later if needed"
          exit 0
          
          # Check if we should skip Airflow deployment
          if [ "${SKIP_AIRFLOW:-false}" = "true" ]; then
            echo "‚è≠Ô∏è  Skipping Airflow deployment as requested"
            exit 0
          fi
          
          # Clean up any stuck Helm operations
          echo "üßπ Cleaning up any stuck Helm operations..."
          helm list -n airflow | grep airflow && {
            echo "Found existing Airflow release, cleaning up..."
            helm uninstall airflow -n airflow || echo "Cleanup failed, continuing..."
          }
          
          helm repo add apache-airflow https://airflow.apache.org
          helm repo update
          
          # Check available versions
          echo "üìã Checking available Airflow Helm chart versions..."
          helm search repo apache-airflow/airflow --versions | head -10
          
          # Try to install with specific version and better error handling
          echo "Installing Airflow with specific version..."
          
          # Use timeout to prevent hanging
          timeout 15m helm upgrade --install airflow apache-airflow/airflow \
            --version 1.12.0 \
            -f k8s/airflow/values.yaml \
            --namespace airflow \
            --create-namespace \
            --wait --timeout 10m || {
            echo "‚ö†Ô∏è  Failed with specific version, trying latest version..."
            timeout 15m helm upgrade --install airflow apache-airflow/airflow \
              -f k8s/airflow/values.yaml \
              --namespace airflow \
              --create-namespace \
              --wait --timeout 10m || {
              echo "‚ùå Failed to deploy Airflow with both versions"
              echo "Trying minimal configuration..."
              timeout 15m helm upgrade --install airflow apache-airflow/airflow \
                --set executor=KubernetesExecutor \
                --set web.service.type=LoadBalancer \
                --set workers.replicas=2 \
                --namespace airflow \
                --create-namespace \
                --wait --timeout 10m || {
                echo "‚ùå Failed to deploy Airflow with minimal config"
                echo "‚ö†Ô∏è  Skipping Airflow deployment and continuing with other components..."
              }
            }
          }
          echo "‚úÖ Airflow deployment attempt completed"
      - name: Monitor Airflow deployment
        run: |
          echo "üîç Monitoring Airflow deployment progress..."
          
          # Wait a bit for resources to be created
          sleep 30
          
          # Check if namespace was created
          if kubectl get namespace airflow; then
            echo "‚úÖ Airflow namespace created"
            
            # Check for pods
            echo "üìä Checking Airflow pods..."
            kubectl get pods -n airflow || echo "‚ö†Ô∏è  No pods found yet"
            
            # Check for services
            echo "üìä Checking Airflow services..."
            kubectl get services -n airflow || echo "‚ö†Ô∏è  No services found yet"
            
            # Check for deployments
            echo "üìä Checking Airflow deployments..."
            kubectl get deployments -n airflow || echo "‚ö†Ô∏è  No deployments found yet"
            
          else
            echo "‚ùå Airflow namespace not found"
          fi
      - name: Verify Airflow deployment
        run: |
          echo "üîç Verifying Airflow deployment..."
          kubectl get pods -n airflow || {
            echo "‚ö†Ô∏è  Airflow pods not found, checking if deployment exists..."
            kubectl get deployments -n airflow || {
              echo "‚ùå Airflow deployment failed completely"
              echo "Continuing with other deployments..."
            }
          }
      - name: Install yq
        run: |
          sudo wget https://github.com/mikefarah/yq/releases/download/v4.43.1/yq_linux_amd64 -O /usr/bin/yq
          sudo chmod +x /usr/bin/yq
      - name: Substitute ECR_IMAGE_URI in model API deployment
        run: |
          echo "üîß Substituting ECR image URI in deployment..."
          export ECR_IMAGE_URI="$AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/$ECR_REPO_API:latest"
          echo "Using ECR Image URI: $ECR_IMAGE_URI"
          
          # Create the substituted deployment file
          yq e '.spec.template.spec.containers[0].image = env(ECR_IMAGE_URI)' k8s/model_api/deployment.yaml > k8s/model_api/deployment.sub.yaml
          
          # Verify the substitution worked
          echo "üîç Verifying image substitution..."
          grep -q "$ECR_IMAGE_URI" k8s/model_api/deployment.sub.yaml && {
            echo "‚úÖ Image URI substituted successfully"
            cat k8s/model_api/deployment.sub.yaml
          } || {
            echo "‚ùå Image URI substitution failed, trying alternative approach with sed..."
            # Alternative approach using sed
            sed "s|<ECR_IMAGE_URI>|$ECR_IMAGE_URI|g" k8s/model_api/deployment.yaml > k8s/model_api/deployment.sub.yaml
            
            # Verify the alternative substitution worked
            grep -q "$ECR_IMAGE_URI" k8s/model_api/deployment.sub.yaml && {
              echo "‚úÖ Image URI substituted successfully using sed"
              cat k8s/model_api/deployment.sub.yaml
            } || {
              echo "‚ùå Both yq and sed substitution failed"
              echo "Original deployment file:"
              cat k8s/model_api/deployment.yaml
              echo "Substituted deployment file:"
              cat k8s/model_api/deployment.sub.yaml
              exit 1
            }
          }
      - name: Deploy Model API
        run: |
          echo "Deploying Model API..."
          kubectl apply -f k8s/model_api/deployment.sub.yaml || {
            echo "‚ùå Failed to deploy Model API deployment"
            exit 1
          }
          kubectl apply -f k8s/model_api/service.yaml || {
            echo "‚ùå Failed to deploy Model API service"
            exit 1
          }
          
          # Wait a moment for the service to be created
          sleep 10
          
          # Verify the service was created correctly
          echo "üîç Verifying Model API service..."
          kubectl get service model-api -o yaml
          
          echo "‚úÖ Model API deployed successfully"
      - name: Check Model API deployment status
        run: |
          echo "üîç Checking Model API deployment status..."
          
          # Check deployment status
          echo "üìä Model API deployment:"
          kubectl get deployment model-api
          
          # Check pod status
          echo "üìä Model API pods:"
          kubectl get pods -l app=model-api
          
          # Check service status
          echo "üìä Model API service:"
          kubectl get service model-api
          
          # Check if pods are ready
          READY_PODS=$(kubectl get pods -l app=model-api --no-headers | grep -c "Running")
          TOTAL_PODS=$(kubectl get pods -l app=model-api --no-headers | wc -l)
          echo "üìä Pod status: $READY_PODS/$TOTAL_PODS pods ready"
          
          # Check why pods are pending
          echo "üîç Diagnosing pod scheduling issues..."
          kubectl describe pods -l app=model-api
          
          # Check node resources
          echo "üìä Node resources:"
          kubectl describe nodes | grep -A 10 "Allocated resources" || echo "‚ö†Ô∏è  Could not get node resource information"
          
          # Check if there are any nodes available
          echo "üìä Available nodes:"
          kubectl get nodes
          
          # Check EKS node group status
          echo "üîç Checking EKS node group status..."
          aws eks describe-nodegroup \
            --cluster-name $EKS_CLUSTER_NAME \
            --nodegroup-name "$EKS_CLUSTER_NAME-node-group" \
            --region $AWS_REGION || {
            echo "‚ùå Node group not found or not accessible"
            echo "üîç Listing all node groups:"
            aws eks list-nodegroups --cluster-name $EKS_CLUSTER_NAME --region $AWS_REGION || echo "No node groups found"
          }
          
          # Check if nodes are joining the cluster
          echo "üîç Checking if nodes are joining the cluster..."
          kubectl get nodes -o wide
          
          if [ "$READY_PODS" -gt 0 ]; then
            echo "‚úÖ Model API deployment is progressing"
          else
            echo "‚ö†Ô∏è  Model API pods not ready yet - checking for scheduling issues"
            echo "üîç This might be due to:"
            echo "  1. Node group not created yet"
            echo "  2. Nodes not ready to accept pods"
            echo "  3. Insufficient resources"
            echo "  4. Network connectivity issues"
          fi
      - name: Wait for deployments to be ready
        run: |
          echo "‚è≥ Waiting for deployments to be ready..."
          
          # Wait for Model API deployment
          echo "‚è≥ Waiting for Model API deployment to be ready..."
          kubectl wait --for=condition=available --timeout=300s deployment/model-api || {
            echo "‚ö†Ô∏è  Model API not ready within timeout, but continuing..."
          }
          
          # Check if Airflow namespace exists before waiting for it
          if kubectl get namespace airflow 2>/dev/null; then
            echo "‚è≥ Waiting for Airflow webserver deployment to be ready..."
            kubectl wait --for=condition=available --timeout=300s deployment/airflow-webserver -n airflow || {
              echo "‚ö†Ô∏è  Airflow webserver not ready within timeout, but continuing..."
            }
          else
            echo "‚è≠Ô∏è  Airflow namespace not found, skipping Airflow wait"
          fi
          
          echo "‚úÖ Deployment wait completed!"
      - name: Deployment Complete
        run: |
          echo "üéâ Complete deployment pipeline finished successfully!"
          echo "Infrastructure: ‚úÖ"
          echo "Data uploaded: ‚úÖ"
          echo "Applications deployed: ‚úÖ"
          
          # Get service information
          echo ""
          echo "üìã Deployment Summary:"
          echo "S3 Bucket: ${{ needs.check-infra.outputs.s3_bucket_name }}"
          echo "EKS Cluster: ${{ needs.check-infra.outputs.eks_cluster_name }}"
          
          # Get service endpoints
          kubectl get services -o wide || echo "‚ö†Ô∏è  Could not get service information"
          
          echo ""
          echo "üåê API Access Information:"
          echo "=========================="
          
          # Get Model API service details
          echo "üìä Model API Service:"
          kubectl get service model-api -o wide || echo "‚ö†Ô∏è  Could not get Model API service"
          
          # Get the external IP/load balancer URL
          MODEL_API_URL=$(kubectl get service model-api -o jsonpath='{.status.loadBalancer.ingress[0].hostname}' 2>/dev/null || echo "Not available")
          MODEL_API_PORT=$(kubectl get service model-api -o jsonpath='{.spec.ports[0].port}' 2>/dev/null || echo "5000")
          
          echo ""
          echo "üîó Model API Endpoints:"
          echo "  Base URL: http://$MODEL_API_URL:$MODEL_API_PORT"
          echo "  Health Check: http://$MODEL_API_URL:$MODEL_API_PORT/health"
          echo "  Predict: http://$MODEL_API_URL:$MODEL_API_PORT/predict"
          
          echo ""
          echo "üìù Example API Usage:"
          echo "  # Health check"
          echo "  curl http://$MODEL_API_URL:$MODEL_API_PORT/health"
          echo ""
          echo "  # Make a prediction"
          echo "  curl -X POST http://$MODEL_API_URL:$MODEL_API_PORT/predict \\"
          echo "    -H 'Content-Type: application/json' \\"
          echo "    -d '{\"features\": [1, 2, 3, 4, 5, 6]}'"
          
          echo ""
          echo "üîß Troubleshooting:"
          echo "  # Check if pods are running"
          echo "  kubectl get pods -l app=model-api"
          echo ""
          echo "  # Check service status"
          echo "  kubectl get service model-api"
          echo ""
          echo "  # View logs"
          echo "  kubectl logs -l app=model-api"
          
          # Save the API URL to a file for easy access
          echo "http://$MODEL_API_URL:$MODEL_API_PORT" > api_endpoint.txt
          echo "API endpoint saved to api_endpoint.txt" 